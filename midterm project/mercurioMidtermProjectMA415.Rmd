---
title: "MA415 Midterm Project"
author: "Katherine Mercurio"
date: "March 22, 2017"
output: html_document
---
Project Overview/ PART 1: 

At first, I tried a bunch of different techniques to merge every data table togther. But, I realized there were too many variables that didn't relate, and it would have made the dataset hard to analyze. Since the data is meant to be prepard to study dangerous places to work, I focused on attributes that give the best picture of dangerous work places. I determined which columns are of interest by observing which ones have distinguishing levels, attributes, or are important for determining danger. I also deleted any incidents that affected zero people, because I believe danger is most relevant when it affected people. If additional information about companies is needed, one can use the activityno to find corresponding information. My tidy dataset prepares the data for analysis because it deletes duplicates and simplifies information into one table to best compare the most dangerous places to work in MA. 

PART 2:
```{r}
library(foreign)
library(dplyr)
osha <- read.dbf("osha.DBF")
viol <- read.dbf("viol.DBF")
subViol <- viol[ ,c("ACTIVITYNO","NUMEXPOSED", "GRAVITY", "ISSUANCE", "CITATION", "VIOLTYPE")]
subViolU <- subViol[ ,c("ACTIVITYNO", "ISSUANCE")]
subViolU <- distinct(subViolU)
subViol <- unique(inner_join(subViolU, subViol))
subOsha <- osha[ ,c("ESTABNAME", "ACTIVITYNO", "PREVACTNO", "PREVCTTYP", "INSPTYPE")]
subOshaU <- distinct(subOsha)
ov <- unique(inner_join(subViol, subOshaU, by = "ACTIVITYNO"))
ov <- filter(ov, NUMEXPOSED > 0)
ov <- distinct(ov)
```
I began by dowloading foreign and dplyr because those are both important libraries to have for my code. Foreign makes reading the dbf files possible. Dplyr makes joins, distinct, unique, and filter possible. I opened up OSHA and viol, and then began subsetting them. I carefully chose attributes I thought were most important based on the lookups text files, the amount of missing (NA) data, and the amount of levels for each attribute. For example, it's important that each company is in MA, because that is the area of interest. But, since all of the accidents in this data set are in MA, each indident doesn't need to list the state, it can be assumed. I noticed a lot of ACTIVITYNO values were repeated, so I believe whoever entered information into the dataset accidentally entered single events multiple times, or created new accidents instead of updating old information. I tried to reduce duplicates by using distinct and unique. I interpreted danger as being relevant to people, since these are workpalces people work at, so I fitlered out any workplace accidents that did not impact people. 

PART 3:
```{r}
accid <- read.dbf("accid.DBF")
ov <- unique(inner_join(ov, accid, by = "ACTIVITYNO"))
ov <- ov[ ,c("ACTIVITYNO", "ESTABNAME", "GRAVITY", "NAME.x", "SEX.x", "DEGREE.x", "NATURE.x", "BODYPART.x", "SOURCE.x") ]
acc <- read.dbf("./lookups/acc.dbf")
acc1 <- acc[1:31,]
library(BBmisc)
ov <- unique(left_join(ov, acc1, by = c("BODYPART.x" = "CODE")))
ov <- BBmisc:: dropNamed(ov, "BODYPART.x") #dropped columns that were no longer needed
ov <- BBmisc:: dropNamed(ov, "CATEGORY.y")
ov <- BBmisc:: dropNamed(ov, "VALUE.y")
acc2 <- acc[84:105, ]
ov <- left_join(ov, acc2, by = c("NATURE.x" = "CODE"))
acc3 <- acc[106:153, ]
ov <- left_join(ov, acc3, by = c("SOURCE.x" = "CODE"))
library(plyr)

ov <- rename(ov, c("VALUE.x"="BodyPart", "VALUE.y"="EnvFact", "VALUE" = "InjurySource"))
ov <- BBmisc:: dropNamed(ov, "NATURE.x")
ov <- BBmisc:: dropNamed(ov, "SOURCE.x")
ov <- BBmisc:: dropNamed(ov, "CATEGORY.x")
ov <- BBmisc:: dropNamed(ov, "CATEGORY.y")
ov <- BBmisc:: dropNamed(ov, "CATEGORY")
```
Here, I began by reading in the accid file so that I could attach more information about each accident to the data frame. I again used read.dbf() to read in this file, used inner_join to attach the columns of accid to ov. I created a subset of ov  to refine the columns I was using. I joined by activity number, and then replaced each code with what the code represents (ex: 01 = body part that corresponds to 01). This makes the table much easier to interpret because the name of the body part is much more important than its code. I continued this process with nature and source codes. Then, I renamed the columns using plyr and deleted extra columns using the dropNamed function from the BBmisc library. 

PART 4:
```{r}
library(tidyr)
viol <- viol[, c("ACTIVITYNO", "ISSUEDATE")]
ov <- unique(inner_join(ov, viol))
ov <- separate(ov, ISSUEDATE,c("Year", "Month", "Day"), "-")
```
I added the Issue date to the ov datatable. I split the date up into three columns so one could analyze trends in months and years. 

PART 5:
```{r}
library(ggplot2)
graph1 <- ggplot(ov, aes(Year, BodyPart))
graph1
graph2 <- ggplot(ov, aes(BodyPart)) + geom_bar(aes(fill = DEGREE.x))
graph2
```

 Graph 2 shows the data in my ov datatable, illustrating which body part is harmed most frequently. A degree of 0 means the degree was missing, NA, or entered as 0. 1 means fatality. 